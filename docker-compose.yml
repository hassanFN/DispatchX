version: "3.8"

services:
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      CLUSTER_ID: ${CLUSTER_ID}
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG4J_OPTS: "-Dlog4j.configuration=file:/tmp/custom-log4j.properties"
    volumes:
      - kafka_data:/var/lib/kafka/data
      - ./kafka-log4j.properties:/tmp/custom-log4j.properties
    networks:
      - kafka_net
    restart: unless-stopped
    command:
      - bash
      - -c
      - |
        if [ ! -f /var/lib/kafka/data/meta.properties ]; then
          echo "Formatting KRaft storage..."
          kafka-storage format --ignore-formatted --cluster-id=$CLUSTER_ID
        fi
        /etc/confluent/docker/run

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka:9092"
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
    networks:
      - kafka_net
    restart: unless-stopped

  dispatcher_service:
    build: ./backend/dispatcher_service
    volumes:
      - ./backend/dispatcher_service:/app
    ports:
      - "8000:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - kafka
      - schema-registry
    #env_file: .env  
    restart: always
    environment:
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL}
      DISPATCH_TOPIC: ${DISPATCH_TOPIC}
      DLQ_TOPIC: ${DLQ_TOPIC}
      DEBUG: ${DEBUG}
      GOOGLE_MAPS_API_KEY: ${GOOGLE_MAPS_API_KEY} # Added Google Maps API key
    networks:
      - kafka_net

  send_test_service:
    build: ./backend/send_test_service
    volumes:
      - ./backend/send_test_service:/app
    depends_on:
      - kafka
      - schema-registry
    #env_file: .env 
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    environment:
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL}
      DISPATCH_TOPIC: ${DISPATCH_TOPIC}
    networks:
      - kafka_net

  dlq_web_app:
    build: ./backend/dlq_web_app
    volumes:
      - ./backend/dlq_web_app:/app
    depends_on:
      - kafka
    #env_file: .env 
    ports:
      - "5050:5050"
    environment:
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      DLQ_TOPIC: ${DLQ_TOPIC}
      GROUP_ID: ${GROUP_ID}
      #add google maps api $ API_KEY and then add the actual key in the .env file (task done but test it)
      GOOGLE_MAPS_API_KEY: ${GOOGLE_MAPS_API_KEY}
    networks:
      - kafka_net

volumes:
  kafka_data:

networks:
  kafka_net:




